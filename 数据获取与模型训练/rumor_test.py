#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
rumor_test.py - è°£è¨€æ£€æµ‹æ¨¡å‹æµ‹è¯•è„šæœ¬
ç”¨äºåŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹
"""

import os
import sys
import argparse
import csv
from collections import defaultdict
from datetime import datetime

# å¯¼å…¥æ¨¡å‹
from rumor_detect_model import RumorDetector


def read_formatted_csv(content_path, comments_path):
    """è¯»å–æ ¼å¼åŒ–çš„CSVæ•°æ®"""
    contents = {}
    with open(content_path, "r", encoding="utf-8") as f:
        rd = csv.reader(f)
        for row in rd:
            if not row:
                continue
            cid = row[0]
            text = row[2]
            ts = int(float(row[4])) if row[4] else 0
            dt = datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M:%S") if ts else ""
            contents[cid] = {"text": text, "time": dt}

    groups = defaultdict(list)
    with open(comments_path, "r", encoding="utf-8") as f:
        rd = csv.reader(f)
        for row in rd:
            if not row:
                continue
            wid = row[1]
            ts = int(float(row[4])) if row[4] else 0
            dt = datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M:%S") if ts else ""
            groups[wid].append({"text": row[3], "time": dt, "name": row[2], "reply2": ""})

    ordered = []
    for cid, content in contents.items():
        ordered.append((cid, content, groups.get(cid, [])))
    return ordered


def main():
    parser = argparse.ArgumentParser(description="æµ‹è¯•è°£è¨€æ£€æµ‹æ¨¡å‹")
    parser.add_argument("--content-path", required=True, help="å¾®åšå†…å®¹CSVæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--comment-path", required=True, help="è¯„è®ºæ•°æ®CSVæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model-path", required=True, help="è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„")
    parser.add_argument("--output-path", required=True, help="é¢„æµ‹ç»“æœè¾“å‡ºè·¯å¾„")

    args = parser.parse_args()

    print("ğŸ§ª å¼€å§‹æµ‹è¯•è°£è¨€æ£€æµ‹æ¨¡å‹...")
    print(f"ğŸ“ å†…å®¹æ–‡ä»¶: {args.content_path}")
    print(f"ğŸ“ è¯„è®ºæ–‡ä»¶: {args.comment_path}")
    print(f"ğŸ¤– æ¨¡å‹æ–‡ä»¶: {args.model_path}")

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model_path}")
        return 1

    # åŠ è½½æ•°æ®
    try:
        rows = read_formatted_csv(args.content_path, args.comment_path)
        print(f"âœ… åŠ è½½æ•°æ®: {len(rows)} æ¡å¾®åš")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return 1

    # åŠ è½½æ¨¡å‹
    try:
        detector = RumorDetector()
        detector.load(args.model_path)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return 1

    # è¿›è¡Œé¢„æµ‹
    try:
        with open(args.output_path, "w", newline="", encoding="utf-8") as f:
            wr = csv.writer(f)
            wr.writerow(["content_id", "prediction", "confidence"])

            total = len(rows)
            for i, (cid, content, comments) in enumerate(rows, 1):
                if i % 10 == 0:
                    print(f"ğŸ“Š é¢„æµ‹è¿›åº¦: {i}/{total}")

                pred = detector.predict(content, comments)
                wr.writerow([cid, pred["prediction"], f"{pred['confidence']:.6f}"])

        print(f"âœ… é¢„æµ‹å®Œæˆ! ç»“æœä¿å­˜è‡³: {args.output_path}")
        print(f"ğŸ“„ æ€»å…±é¢„æµ‹: {total} æ¡å¾®åš")

        return 0

    except Exception as e:
        print(f"âŒ é¢„æµ‹è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())