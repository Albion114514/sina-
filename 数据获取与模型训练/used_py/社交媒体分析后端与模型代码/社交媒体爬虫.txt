# spiders/weibo_spider.py
import scrapy
from bs4 import BeautifulSoup
import json
from datetime import datetime


class WeiboSpider(scrapy.Spider):
    name = 'weibo'
    start_urls = ['https://weibo.com']  # 示例URL

    def parse(self, response):
        soup = BeautifulSoup(response.text, 'html.parser')

        # 根据微博页面结构定位帖子 (需要根据实际结构调整)
        posts = soup.find_all('div', class_='WB_feed')  # 示例class

        for post in posts:
            try:
                # 提取文本内容
                text_elem = post.find('div', class_='WB_text')
                text = text_elem.get_text().strip() if text_elem else ''

                # 提取图片
                image_elem = post.find('img', class_='WB_media')
                image_url = image_elem.get('src') if image_elem else None

                # 提取时间
                time_elem = post.find('a', class_='WB_time')
                time_str = time_elem.get_text().strip() if time_elem else ''

                # 提取帖子ID
                post_id = post.get('mid')  # 微博的mid

                if text and post_id:
                    yield {
                        'text': text,
                        'image': image_url,
                        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        'source_platform': 'weibo',
                        'post_id': post_id
                    }

            except Exception as e:
                self.logger.error(f"Error parsing post: {e}")