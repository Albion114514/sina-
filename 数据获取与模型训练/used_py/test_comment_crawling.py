# test_comments.py
# !/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ç§»åŠ¨ç«¯è¯„è®ºçˆ¬å–åŠŸèƒ½
"""

import json
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥ç§»åŠ¨ç«¯çˆ¬è™«
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from weibo_mobile_crawler import WeiboMobileCrawler

    print("âœ… æˆåŠŸå¯¼å…¥ç§»åŠ¨ç«¯çˆ¬è™«")
except ImportError:
    print("âŒ æ— æ³•å¯¼å…¥ç§»åŠ¨ç«¯çˆ¬è™«ï¼Œè¯·ç¡®ä¿ weibo_mobile_crawler.py å­˜åœ¨")
    sys.exit(1)

import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_comment_crawling():
    """æµ‹è¯•ç§»åŠ¨ç«¯è¯„è®ºçˆ¬å–"""
    print("ğŸ§ª æµ‹è¯•ç§»åŠ¨ç«¯è¯„è®ºçˆ¬å–åŠŸèƒ½")
    print("=" * 50)

    # åŠ è½½é…ç½®
    with open('config.json', 'r', encoding='utf-8') as f:
        config = json.load(f)

    print(f"crawl_comments é…ç½®: {config.get('crawl_comments', 'æœªè®¾ç½®')}")

    # åˆ›å»ºç§»åŠ¨ç«¯çˆ¬è™«å®ä¾‹
    crawler = WeiboMobileCrawler()

    # æµ‹è¯•è¿æ¥æ•°æ®åº“
    if crawler.connect_database():
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
    else:
        print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
        return

    # æµ‹è¯•è·å–å…³é”®å­—ID
    keyword = config['keywords'][0]
    keyword_id = crawler.get_keyword_id(keyword)
    print(f"å…³é”®å­— '{keyword}' çš„ID: {keyword_id}")

    # æµ‹è¯•çˆ¬å–ä¸€é¡µæ•°æ®ï¼ˆä½¿ç”¨ç§»åŠ¨ç«¯APIï¼‰
    print(f"\næµ‹è¯•çˆ¬å–å…³é”®è¯: {keyword}")
    weibo_items = crawler.crawl_weibo_search_api(keyword, 1)
    print(f"æ‰¾åˆ° {len(weibo_items)} æ¡å¾®åš")

    # æ˜¾ç¤ºç¬¬ä¸€æ¡å¾®åšçš„è¯¦ç»†ä¿¡æ¯
    if weibo_items:
        test_weibo = weibo_items[0]
        print(f"\nğŸ“ ç¬¬ä¸€æ¡å¾®åšç¤ºä¾‹ï¼š")
        print(f"  ID: {test_weibo['id']}")
        print(f"  ç”¨æˆ·: {test_weibo.get('user_name', 'æœªçŸ¥')}")
        print(f"  å†…å®¹: {test_weibo['text'][:100]}...")
        print(f"  è½¬å‘: {test_weibo.get('reposts_count', 0)}")
        print(f"  è¯„è®º: {test_weibo.get('comments_count', 0)}")
        print(f"  ç‚¹èµ: {test_weibo.get('attitudes_count', 0)}")

    # æµ‹è¯•è¯„è®ºçˆ¬å–
    if weibo_items and config.get('crawl_comments', False):
        test_weibo = weibo_items[0]
        print(f"\næµ‹è¯•çˆ¬å–å¾®åš {test_weibo['id']} çš„è¯„è®º")
        comments = crawler.crawl_weibo_comments_api(test_weibo['id'])
        print(f"è·å–åˆ° {len(comments)} æ¡è¯„è®º")

        if comments:
            saved_count = crawler.save_comments_to_database(comments)
            print(f"æˆåŠŸä¿å­˜ {saved_count} æ¡è¯„è®ºåˆ°æ•°æ®åº“")

            # æ˜¾ç¤ºå‰å‡ æ¡è¯„è®º
            print("\nğŸ“ è¯„è®ºç¤ºä¾‹ï¼š")
            for i, comment in enumerate(comments[:3]):
                print(f"  {i + 1}. {comment['user']}: {comment['content'][:50]}...")

    # æµ‹è¯•ä¿å­˜å¾®åšæ•°æ®
    if weibo_items:
        print(f"\nğŸ’¾ æµ‹è¯•ä¿å­˜å¾®åšæ•°æ®...")
        saved_count = 0
        for item in weibo_items[:2]:  # åªä¿å­˜å‰ä¸¤æ¡æµ‹è¯•
            if crawler.save_to_database(item, keyword_id):
                saved_count += 1
                print(f"  ä¿å­˜å¾®åš: {item['id']}")

        print(f"æˆåŠŸä¿å­˜ {saved_count} æ¡å¾®åšåˆ°æ•°æ®åº“")

    if crawler.db_connection:
        crawler.db_connection.close()
    print("\nâœ… ç§»åŠ¨ç«¯çˆ¬è™«æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    test_comment_crawling()