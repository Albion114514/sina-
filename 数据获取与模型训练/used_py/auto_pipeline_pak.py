#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
auto_pipeline_fixed.py
ä¿®å¤ç‰ˆæœ¬ - æ”¹è¿›ç”¨æˆ·ç•Œé¢ï¼Œæ›´æ¸…æ™°çš„å¼€å±€é€‰é¡¹
"""

import os
import sys
import json
import time
import csv
import shutil
import subprocess
from pathlib import Path
from uuid import uuid4
from datetime import datetime
from typing import Optional, List, Tuple

# ---------- Constants ----------
TRAIN_OUTPUT_DIR = "train_output"
TEST_OUTPUT_DIR = "test_output"

WEIBO_TO_CSV_SCRIPT_CANDIDATES = ["weibo_to_csv.py"]
CRAWLER_SCRIPT_CANDIDATES = [
    "weibo_mobile_crawler_main.py",
    "weibo_crawler_2_1_main.py",
    "weibo_crawler_main.py",
]
ALGO_SCRIPT_CANDIDATES = ["rumor_detect.py"]

CONFIG_PATH = "config.json"


# ---------- Utilities ----------

def ensure_module_or_none(modname: str):
    """Try to import a module; if missing, return None."""
    try:
        return __import__(modname)
    except Exception:
        return None


settings = ensure_module_or_none("settings")


def load_config(path: str = CONFIG_PATH) -> dict:
    """Load config.json; if not present, raise clear error."""
    if settings and hasattr(settings, "load_config"):
        return settings.load_config(path)
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def build_sqlalchemy_uri(cfg: dict) -> str:
    """Return a SQLAlchemy URI built from cfg['mysql_config'] (fallback if settings absent)."""
    if settings and hasattr(settings, "build_sqlalchemy_uri"):
        return settings.build_sqlalchemy_uri(cfg)
    mc = cfg["mysql_config"].copy()
    user = mc.get("user", "root")
    pwd = mc.get("password", "")
    host = mc.get("host", "localhost")
    port = int(mc.get("port", 3306))
    db = mc.get("database", "")
    return f"mysql+pymysql://{user}:{pwd}@{host}:{port}/{db}?charset=utf8mb4"


def run_subprocess(cmd: List[str], cwd: Optional[str] = None) -> Tuple[int, str, str]:
    """Run a subprocess and return (returncode, stdout, stderr)."""
    try:
        p = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='ignore',
            cwd=cwd
        )
        return p.returncode, p.stdout, p.stderr
    except UnicodeDecodeError:
        # å¦‚æœutf-8å¤±è´¥ï¼Œå°è¯•å…¶ä»–ç¼–ç 
        p = subprocess.run(
            cmd,
            capture_output=True,
            cwd=cwd
        )
        stdout = p.stdout.decode('utf-8', errors='ignore')
        stderr = p.stderr.decode('utf-8', errors='ignore')
        return p.returncode, stdout, stderr


def pick_existing(paths: List[str]) -> Optional[str]:
    """Return the first existing path from candidates."""
    for p in paths:
        if Path(p).exists():
            return p
    return None


def slugify(text: str, max_len: int = 32) -> str:
    """Safe slug from text for filesystem names."""
    safe = "".join(ch if ch.isalnum() else "_" for ch in text.strip())
    if not safe:
        safe = "topic"
    return safe[:max_len].strip("_")


def print_header(title: str):
    """æ‰“å°ç¾è§‚çš„æ ‡é¢˜"""
    print("\n" + "=" * 60)
    print(f"ğŸ“‹ {title}")
    print("=" * 60)


def print_step(step_num: int, description: str):
    """æ‰“å°æ­¥éª¤ä¿¡æ¯"""
    print(f"\nğŸ”¹ æ­¥éª¤ {step_num}: {description}")


def print_success(message: str):
    """æ‰“å°æˆåŠŸä¿¡æ¯"""
    print(f"âœ… {message}")


def print_warning(message: str):
    """æ‰“å°è­¦å‘Šä¿¡æ¯"""
    print(f"âš ï¸ {message}")


def print_error(message: str):
    """æ‰“å°é”™è¯¯ä¿¡æ¯"""
    print(f"âŒ {message}")


def print_info(message: str):
    """æ‰“å°ä¸€èˆ¬ä¿¡æ¯"""
    print(f"â„¹ï¸ {message}")


# ---------- DB Helpers (pymysql) ----------

def get_db_conn(cfg: dict):
    import pymysql
    mc = cfg["mysql_config"].copy()
    mc.setdefault("charset", "utf8mb4")
    mc["port"] = int(mc.get("port", 3306))
    return pymysql.connect(**mc)


def bootstrap_schema_if_possible():
    """Run db_bootstrap.py --mode init if it exists; else no-op."""
    if Path("db_bootstrap.py").exists():
        print_step(1, "åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„")
        rc, out, err = run_subprocess([sys.executable, "db_bootstrap.py", "--mode", "init"])
        if rc != 0:
            print_warning("æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ (ç»§ç»­æ‰§è¡Œ):")
            print(err or out)


def recreate_database_tables(cfg: dict) -> bool:
    """é‡æ–°åˆ›å»ºæ‰€æœ‰æ•°æ®åº“è¡¨"""
    try:
        # å°è¯•ä½¿ç”¨ç°æœ‰çš„ä¿®å¤è„šæœ¬
        if Path("db_setup_fixed.py").exists():
            print_info("ä½¿ç”¨ db_setup_fixed.py é‡å»ºè¡¨...")
            rc, out, err = run_subprocess([sys.executable, "db_setup_fixed.py"])
            if rc == 0:
                print_success("è¡¨é‡å»ºæˆåŠŸ")
                return True
            else:
                print_error("è¡¨é‡å»ºå¤±è´¥")
                return False
        elif Path("db_setup2_0.py").exists():
            print_info("ä½¿ç”¨ db_setup2_0.py é‡å»ºè¡¨...")
            rc, out, err = run_subprocess([sys.executable, "db_setup2_0.py"])
            if rc == 0:
                print_success("è¡¨é‡å»ºæˆåŠŸ")
                return True
            else:
                print_error("è¡¨é‡å»ºå¤±è´¥")
                return False
        else:
            print_warning("æœªæ‰¾åˆ°æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬ï¼Œä½¿ç”¨å†…ç½®æ–¹æ³•é‡å»º...")
            return recreate_tables_manual(cfg)
    except Exception as e:
        print_error(f"è¡¨é‡å»ºå¤±è´¥: {e}")
        return False


def recreate_tables_manual(cfg: dict) -> bool:
    """æ‰‹åŠ¨é‡å»ºè¡¨ç»“æ„"""
    try:
        conn = get_db_conn(cfg)
        cursor = conn.cursor()

        print_info("åˆ é™¤å¤–é”®çº¦æŸ...")
        cursor.execute("""
            SELECT CONSTRAINT_NAME, TABLE_NAME 
            FROM information_schema.KEY_COLUMN_USAGE 
            WHERE TABLE_SCHEMA = %s 
            AND REFERENCED_TABLE_NAME IS NOT NULL
        """, (cfg['mysql_config']['database'],))

        foreign_keys = cursor.fetchall()
        for fk_name, table_name in foreign_keys:
            try:
                cursor.execute(f"ALTER TABLE {table_name} DROP FOREIGN KEY {fk_name}")
                print_success(f"åˆ é™¤å¤–é”®: {table_name}.{fk_name}")
            except Exception as e:
                print_warning(f"åˆ é™¤å¤–é”®å¤±è´¥ {table_name}.{fk_name}: {e}")

        # åˆ é™¤è¡¨ï¼ˆæŒ‰ä¾èµ–é¡ºåºï¼‰
        tables_to_drop = [
            'topic_keywords', 'prediction_results', 'comments',
            'weibo_data', 'crawl_log', 'keywords', 'topics'
        ]

        for table in tables_to_drop:
            try:
                cursor.execute(f"DROP TABLE IF EXISTS {table}")
                print_success(f"åˆ é™¤è¡¨: {table}")
            except Exception as e:
                print_warning(f"åˆ é™¤è¡¨å¤±è´¥ {table}: {e}")

        print_info("åˆ›å»ºæ–°è¡¨...")
        # åˆ›å»ºå…³é”®å­—è¡¨
        cursor.execute("""
            CREATE TABLE keywords (
                id INT AUTO_INCREMENT PRIMARY KEY,
                keyword VARCHAR(255) NOT NULL UNIQUE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_keyword (keyword)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """)
        print_success("åˆ›å»ºå…³é”®å­—è¡¨")

        # åˆ›å»ºå¾®åšæ•°æ®è¡¨
        cursor.execute("""
            CREATE TABLE weibo_data (
                id VARCHAR(50) PRIMARY KEY,
                keyword_id INT NOT NULL,
                text TEXT NOT NULL,
                pics TEXT,
                timestamp BIGINT NOT NULL,
                source VARCHAR(100) DEFAULT 'æ–°æµªå¾®åšç§»åŠ¨ç«¯',
                user_name VARCHAR(255) DEFAULT '',
                reposts_count INT DEFAULT 0,
                comments_count INT DEFAULT 0,
                attitudes_count INT DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                INDEX idx_timestamp (timestamp),
                INDEX idx_keyword_id (keyword_id),
                FOREIGN KEY (keyword_id) REFERENCES keywords(id)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """)
        print_success("åˆ›å»ºå¾®åšæ•°æ®è¡¨")

        # åœ¨ recreate_tables_manual() é‡Œã€åˆ›å»º weibo_data ä¹‹åï¼Œç»§ç»­åŠ ä¸Šï¼š

        # comments
        cursor.execute("""
            CREATE TABLE comments (
                id VARCHAR(50) PRIMARY KEY,
                weibo_id VARCHAR(50) NOT NULL,
                user VARCHAR(100),
                content TEXT NOT NULL,
                timestamp BIGINT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                INDEX idx_weibo_id (weibo_id),
                FOREIGN KEY (weibo_id) REFERENCES weibo_data(id)
                    ON DELETE CASCADE ON UPDATE RESTRICT
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """)

        # crawl_log
        cursor.execute("""
            CREATE TABLE crawl_log (
                id INT AUTO_INCREMENT PRIMARY KEY,
                keyword VARCHAR(255) NOT NULL,
                page_num INT NOT NULL,
                crawl_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                success_count INT DEFAULT 0,
                error_message TEXT,
                INDEX idx_keyword (keyword)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """)

        # topics
        cursor.execute("""
            CREATE TABLE topics (
                id INT AUTO_INCREMENT PRIMARY KEY,
                title VARCHAR(255) NOT NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                mode ENUM('train','test') NOT NULL,
                rumor_type TINYINT,
                UNIQUE KEY uk_title (title)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """)

        # topic_keywords
        cursor.execute("""
            CREATE TABLE topic_keywords (
                id INT AUTO_INCREMENT PRIMARY KEY,
                topic_id INT NOT NULL,
                keyword_id INT NOT NULL,
                UNIQUE KEY uk_topic_keyword (topic_id, keyword_id),
                FOREIGN KEY (topic_id) REFERENCES topics(id) ON DELETE CASCADE,
                FOREIGN KEY (keyword_id) REFERENCES keywords(id)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """)

        # prediction_results
        cursor.execute("""
            CREATE TABLE prediction_results (
                id INT AUTO_INCREMENT PRIMARY KEY,
                topic_id INT NOT NULL,
                prediction TEXT NOT NULL,
                accuracy FLOAT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                UNIQUE KEY uk_topic (topic_id),
                FOREIGN KEY (topic_id) REFERENCES topics(id) ON DELETE CASCADE
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
        """)

        # æ’å…¥é»˜è®¤å…³é”®å­—
        keywords = cfg.get('keywords', [])
        for keyword in keywords:
            cursor.execute("INSERT IGNORE INTO keywords (keyword) VALUES (%s)", (keyword,))
        print_success(f"æ’å…¥ {len(keywords)} ä¸ªå…³é”®å­—")

        conn.commit()
        conn.close()
        return True

    except Exception as e:
        print_error(f"æ‰‹åŠ¨é‡å»ºè¡¨å¤±è´¥: {e}")
        return False


# ---------- Core Steps ----------

def get_user_choices(cfg: dict):
    """è·å–ç”¨æˆ·çš„æ‰€æœ‰é€‰æ‹©"""
    print_header("å¾®åšè°£è¨€æ£€æµ‹è‡ªåŠ¨åŒ–ç³»ç»Ÿ")
    print("æ¬¢è¿ä½¿ç”¨è‡ªåŠ¨åŒ–æµç¨‹ï¼è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œé…ç½®ï¼š")

    # æ­¥éª¤1: æ•°æ®åº“è¡¨é‡å»ºé€‰æ‹©
    print_step(1, "æ•°æ®åº“è¡¨é…ç½®")
    print("å½“å‰æ•°æ®åº“çŠ¶æ€ï¼š")
    print("  - å¦‚æœé¦–æ¬¡è¿è¡Œæˆ–éœ€è¦é‡ç½®æ•°æ®ï¼Œè¯·é€‰æ‹©é‡å»º")
    print("  - å¦‚æœå·²æœ‰æ•°æ®å¹¶å¸Œæœ›ä¿ç•™ï¼Œè¯·é€‰æ‹©ä½¿ç”¨ç°æœ‰è¡¨")

    recreate_choice = None
    while recreate_choice not in ("y", "n", "Y", "N"):
        recreate_choice = input("æ˜¯å¦é‡æ–°åˆ›å»ºæ•°æ®åº“è¡¨ï¼Ÿ(y/n): ").strip().lower()

    # æ­¥éª¤2: å…³é”®å­—ç¡®è®¤
    print_step(2, "å…³é”®å­—é…ç½®")
    current_keywords = cfg.get('keywords', [])
    print(f"å½“å‰é…ç½®çš„å…³é”®å­—: {current_keywords}")
    print("è¿™äº›å…³é”®å­—å°†ç”¨äºå¾®åšæœç´¢")

    keyword_choice = None
    while keyword_choice not in ("y", "n", "Y", "N"):
        keyword_choice = input("ç¡®è®¤ä½¿ç”¨è¿™äº›å…³é”®å­—ï¼Ÿ(y/n): ").strip().lower()

    if keyword_choice != "y":
        print("è¯·ä¿®æ”¹ config.json æ–‡ä»¶ä¸­çš„ keywords é…ç½®åé‡æ–°è¿è¡Œç¨‹åºã€‚")
        sys.exit(1)

    # æ­¥éª¤3: æ¨¡å¼é€‰æ‹©
    print_step(3, "è¿è¡Œæ¨¡å¼é€‰æ‹©")
    print("è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼ï¼š")
    print("  - è®­ç»ƒæ¨¡å¼ (1): ç”¨äºè®­ç»ƒæ¨¡å‹ï¼Œéœ€è¦æŒ‡å®šå†…å®¹ç±»å‹")
    print("  - æµ‹è¯•æ¨¡å¼ (2): ç”¨äºæµ‹è¯•æ¨¡å‹ï¼Œä¸éœ€è¦æŒ‡å®šå†…å®¹ç±»å‹")

    mode = None
    while mode not in ("1", "2"):
        mode = input("è¯·é€‰æ‹©æ¨¡å¼ (1:è®­ç»ƒ, 2:æµ‹è¯•): ").strip()
    mode = "train" if mode == "1" else "test"

    # æ­¥éª¤4: å¦‚æœæ˜¯è®­ç»ƒæ¨¡å¼ï¼Œé€‰æ‹©å†…å®¹ç±»å‹
    rumor_type = None
    if mode == "train":
        print_step(4, "è®­ç»ƒå†…å®¹ç±»å‹é€‰æ‹©")
        print("è¯·é€‰æ‹©è®­ç»ƒæ•°æ®çš„ç±»å‹ï¼š")
        print("  - è°£è¨€ (1): æ ‡è®°ä¸ºè°£è¨€çš„æ•°æ®")
        print("  - éè°£è¨€ (2): æ ‡è®°ä¸ºéè°£è¨€çš„æ•°æ®")

        rt = None
        while rt not in ("1", "2"):
            rt = input("è¯·é€‰æ‹©å†…å®¹ç±»å‹ (1:è°£è¨€, 2:éè°£è¨€): ").strip()
        rumor_type = int(rt)

    # æ­¥éª¤5: è¾“å…¥å¤§æ ‡é¢˜
    print_step(5, "ä¸»é¢˜å‘½å")
    print("è¯·è¾“å…¥æœ¬æ¬¡ä»»åŠ¡çš„å¤§æ ‡é¢˜ï¼š")
    print("  - è¿™å°†ç”¨äºåˆ›å»ºè¾“å‡ºç›®å½•å’Œæ•°æ®åº“è®°å½•")
    print("  - å»ºè®®ä½¿ç”¨æœ‰æ„ä¹‰çš„åç§°ï¼Œå¦‚'çº¢å†›åŸå¤§æ·è°£è¨€æ£€æµ‹'")

    topic_title = ""
    while not topic_title.strip():
        topic_title = input("è¯·è¾“å…¥å¤§æ ‡é¢˜: ").strip()
        if not topic_title.strip():
            print_warning("å¤§æ ‡é¢˜ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥")

    return {
        'recreate_tables': recreate_choice == 'y',
        'keywords_confirmed': keyword_choice == 'y',
        'mode': mode,
        'rumor_type': rumor_type,
        'topic_title': topic_title,
        'keywords': current_keywords
    }


def ensure_keywords(cur, keywords: List[str]) -> List[int]:
    """Ensure keywords exist; return their IDs in order."""
    ids: List[int] = []
    for k in keywords:
        cur.execute("SELECT id FROM keywords WHERE keyword=%s", (k,))
        row = cur.fetchone()
        if row:
            ids.append(int(row[0]))
        else:
            cur.execute("INSERT INTO keywords (keyword) VALUES (%s)", (k,))
            ids.append(int(cur.lastrowid))
    return ids


def save_topic_and_link_keywords(conn, title: str, mode: str, rumor_type: Optional[int], kw_list: List[str]) -> int:
    """Insert or update topic, link to keywords in topic_keywords; return topic_id."""
    with conn.cursor() as cur:
        # upsert topic
        cur.execute(
            """
            INSERT INTO topics (title, mode, rumor_type)
            VALUES (%s, %s, %s)
            ON DUPLICATE KEY UPDATE mode=VALUES(mode), rumor_type=VALUES(rumor_type)
            """,
            (title, mode, rumor_type),
        )
        if cur.lastrowid:
            topic_id = int(cur.lastrowid)
        else:
            cur.execute("SELECT id FROM topics WHERE title=%s", (title,))
            topic_id = int(cur.fetchone()[0])

        # ensure keywords and link
        kw_ids = ensure_keywords(cur, kw_list)
        for kid in kw_ids:
            cur.execute(
                """
                INSERT IGNORE INTO topic_keywords (topic_id, keyword_id)
                VALUES (%s, %s)
                """,
                (topic_id, kid),
            )
    conn.commit()
    return topic_id


def run_crawler():
    """Run the crawler script (pick the first that exists)."""
    crawler = pick_existing(CRAWLER_SCRIPT_CANDIDATES)
    if not crawler:
        print_warning("æœªæ‰¾åˆ°çˆ¬è™«è„šæœ¬ï¼Œè¯·å°†çˆ¬è™«è„šæœ¬å‘½åä¸ºä»¥ä¸‹ä¹‹ä¸€å¹¶æ”¾åœ¨å½“å‰ç›®å½•ï¼š")
        for c in CRAWLER_SCRIPT_CANDIDATES:
            print("  -", c)
        return False

    print_step(6, "è¿è¡Œå¾®åšçˆ¬è™«")
    print_info(f"ä½¿ç”¨çˆ¬è™«è„šæœ¬: {crawler}")
    rc, out, err = run_subprocess([sys.executable, crawler])

    if rc != 0:
        print_error("çˆ¬è™«è¿è¡Œå¤±è´¥ï¼š")
        print(err or out)
        return False

    print_success("çˆ¬è™«è¿è¡Œå®Œæˆ")
    print(out)
    return True


def create_unique_output_dir(mode: str, topic_title: str) -> Path:
    base = TRAIN_OUTPUT_DIR if mode == "train" else TEST_OUTPUT_DIR
    Path(base).mkdir(exist_ok=True)
    stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    slug = slugify(topic_title, max_len=24)
    unique = f"{stamp}_{slug}_{uuid4().hex[:6]}"
    outdir = Path(base) / unique
    outdir.mkdir(parents=True, exist_ok=False)
    print_success(f"è¾“å‡ºç›®å½•: {outdir}")
    return outdir


def run_weibo_to_csv(outdir: Path) -> bool:
    """Run weibo_to_csv export into outdir; expects script exists."""
    tool = pick_existing(WEIBO_TO_CSV_SCRIPT_CANDIDATES)
    if not tool:
        print_warning("æœªæ‰¾åˆ° weibo_to_csv.pyï¼Œè¯·å°†è„šæœ¬æ”¾åœ¨å½“å‰ç›®å½•")
        return False

    print_step(7, "å¯¼å‡ºæ•°æ®åˆ°CSV")
    print_info(f"ä½¿ç”¨å¯¼å‡ºè„šæœ¬: {tool}")
    rc, out, err = run_subprocess([sys.executable, tool, "--output", str(outdir)])

    if rc != 0:
        print_error("å¯¼å‡ºå¤±è´¥ï¼š")
        print(err or out)
        return False

    print_success("æ•°æ®å¯¼å‡ºå®Œæˆ")
    print(out)
    return True


def run_algorithm(mode: str, rumor_type: Optional[int], outdir: Path) -> Tuple[bool, Optional[float]]:
    """
    Run algorithm component on generated CSVs.
    Expected inputs:
      - weibo_data_format.csv
      - comments_format.csv
    Output:
      - prediction_result.csv
    Return (ok, accuracy) where accuracy can be None if not found.
    """
    algo = pick_existing(ALGO_SCRIPT_CANDIDATES)
    if not algo:
        print_warning("æœªæ‰¾åˆ°ç®—æ³•è„šæœ¬ rumor_detect.pyï¼›å°†è·³è¿‡ç®—æ³•æ­¥éª¤ã€‚")
        return False, None

    content = outdir / "weibo_data_format.csv"
    comments = outdir / "comments_format.csv"
    output = outdir / "prediction_result.csv"

    if not content.exists() or not comments.exists():
        print_warning("ç®—æ³•è¾“å…¥ CSV ç¼ºå¤±ï¼šéœ€è¦ weibo_data_format.csv å’Œ comments_format.csv")
        return False, None

    cmd = [
        sys.executable, str(algo),
        "--content", str(content),
        "--comments", str(comments),
        "--output", str(output),
        "--mode", "train" if mode == "train" else "test"
    ]
    if mode == "train" and rumor_type in (1, 2):
        cmd.extend(["--label", str(rumor_type)])

    print_step(8, "è¿è¡Œè°£è¨€æ£€æµ‹ç®—æ³•")
    print_info("è¿è¡Œå‘½ä»¤: " + " ".join(cmd))
    rc, out, err = run_subprocess(cmd)

    if rc != 0:
        print_error("ç®—æ³•è¿è¡Œå¤±è´¥ï¼š")
        print(err or out)
        return False, None

    # Try parse accuracy from stdout (e.g., "Accuracy: 0.89")
    acc = None
    for line in (out or "").splitlines():
        if "Accuracy" in line:
            try:
                acc = float(line.split(":")[-1].strip())
            except Exception:
                pass

    print_success("ç®—æ³•è¿è¡Œå®Œæˆ")
    print(out)
    return True, acc


def save_prediction(conn, topic_id: int, outdir: Path, accuracy: Optional[float]) -> bool:
    """Read prediction_result.csv content and store into prediction_results table (1:1 topic)."""
    pred_path = outdir / "prediction_result.csv"
    if not pred_path.exists():
        print_warning("æ‰¾ä¸åˆ° prediction_result.csvï¼Œå†™åº“å°†è·³è¿‡")
        return False

    content = pred_path.read_text(encoding="utf-8", errors="ignore")

    with conn.cursor() as cur:
        cur.execute(
            """
            INSERT INTO prediction_results (topic_id, prediction, accuracy)
            VALUES (%s, %s, %s)
            ON DUPLICATE KEY UPDATE
                prediction=VALUES(prediction),
                accuracy=VALUES(accuracy)
            """,
            (topic_id, content, accuracy),
        )
    return True


def write_topic_info_csv(conn, topic_id: int, outdir: Path) -> None:
    """Write topic_info.csv with topic + prediction join into outdir."""
    with conn.cursor() as cur:
        cur.execute(
            """
            SELECT t.title, t.mode, t.rumor_type, p.prediction, p.accuracy, t.created_at
            FROM topics t
            LEFT JOIN prediction_results p ON t.id = p.topic_id
            WHERE t.id = %s
            """,
            (topic_id,),
        )
        row = cur.fetchone()

    csv_path = outdir / "topic_info.csv"
    with open(csv_path, "w", encoding="utf-8-sig", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["title", "mode", "rumor_type", "prediction", "accuracy", "created_at"])
        if row:
            writer.writerow(row)


def main():
    # åŠ è½½é…ç½®
    cfg = load_config()

    # è·å–ç”¨æˆ·é€‰æ‹©
    choices = get_user_choices(cfg)

    # æ•°æ®åº“è¡¨å¤„ç†
    if choices['recreate_tables']:
        print_info("é‡æ–°åˆ›å»ºæ•°æ®åº“è¡¨...")
        if recreate_database_tables(cfg):
            print_success("æ•°æ®åº“è¡¨é‡å»ºå®Œæˆ")
        else:
            print_error("æ•°æ®åº“è¡¨é‡å»ºå¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨ç°æœ‰è¡¨")
    else:
        print_info("ä½¿ç”¨ç°æœ‰æ•°æ®åº“è¡¨")
        bootstrap_schema_if_possible()

    # æ•°æ®åº“è¿æ¥
    conn = get_db_conn(cfg)
    try:
        # ä¿å­˜ä¸»é¢˜å’Œå…³è”å…³é”®å­—
        print_step(9, "ä¿å­˜ä¸»é¢˜ä¿¡æ¯åˆ°æ•°æ®åº“")
        topic_id = save_topic_and_link_keywords(
            conn,
            choices['topic_title'],
            choices['mode'],
            choices['rumor_type'],
            choices['keywords']
        )
        print_success(f"ä¸»é¢˜ä¿å­˜æˆåŠŸï¼ŒID: {topic_id}")

        # è¿è¡Œçˆ¬è™«
        if not run_crawler():
            yn = input("çˆ¬è™«è¿è¡Œå¤±è´¥ï¼Œæ˜¯å¦ç»§ç»­åç»­æ­¥éª¤? (y/n): ").strip().lower()
            if yn != "y":
                sys.exit(1)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        outdir = create_unique_output_dir(choices['mode'], choices['topic_title'])

        # å¯¼å‡ºCSV
        if not run_weibo_to_csv(outdir):
            yn = input("å¯¼å‡ºå¤±è´¥ï¼Œæ˜¯å¦ç»§ç»­ç®—æ³•æ­¥éª¤? (y/n): ").strip().lower()
            if yn != "y":
                sys.exit(1)

        # è¿è¡Œç®—æ³•
        ok_algo, acc = run_algorithm(choices['mode'], choices['rumor_type'], outdir)
        if not ok_algo:
            print_warning("ç®—æ³•æœªæˆåŠŸæ‰§è¡Œï¼Œæ•°æ®åº“è®°å½•å°†ä¸åŒ…å«é¢„æµ‹å†…å®¹/å‡†ç¡®ç‡")

        # ä¿å­˜é¢„æµ‹ç»“æœåˆ°æ•°æ®åº“
        print_step(10, "ä¿å­˜é¢„æµ‹ç»“æœåˆ°æ•°æ®åº“")
        if save_prediction(conn, topic_id, outdir, acc):
            print_success("é¢„æµ‹ç»“æœä¿å­˜æˆåŠŸ")
        else:
            print_warning("é¢„æµ‹ç»“æœä¿å­˜å¤±è´¥")

        # å†™å…¥topic_info.csv
        print_step(11, "ç”Ÿæˆä¸»é¢˜ä¿¡æ¯æ–‡ä»¶")
        write_topic_info_csv(conn, topic_id, outdir)
        print_success("ä¸»é¢˜ä¿¡æ¯æ–‡ä»¶ç”Ÿæˆå®Œæˆ")

        # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
        print_header("æµç¨‹å®Œæˆ")
        print_success(f"æ‰€æœ‰æ“ä½œå·²å®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {outdir}")
        print(f"ğŸ” ä¸»é¢˜æ ‡é¢˜: {choices['topic_title']}")
        print(f"ğŸ“Š è¿è¡Œæ¨¡å¼: {choices['mode']}")
        if choices['mode'] == 'train':
            print(f"ğŸ·ï¸  å†…å®¹ç±»å‹: {'è°£è¨€' if choices['rumor_type'] == 1 else 'éè°£è¨€'}")
        print(f"ğŸ”‘ ä½¿ç”¨å…³é”®å­—: {', '.join(choices['keywords'])}")
        print("\nğŸ‰ æ‚¨ç°åœ¨å¯ä»¥æŸ¥çœ‹è¾“å‡ºç›®å½•ä¸­çš„ç»“æœæ–‡ä»¶ï¼")

    except Exception as e:
        print_error(f"æµç¨‹æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        conn.close()


if __name__ == "__main__":
    main()